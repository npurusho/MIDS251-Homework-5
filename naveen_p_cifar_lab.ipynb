{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cace261f",
      "metadata": {
        "id": "cace261f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d693cd6c",
      "metadata": {
        "id": "d693cd6c"
      },
      "outputs": [],
      "source": [
        "SEED=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "363e2b75",
      "metadata": {
        "id": "363e2b75"
      },
      "outputs": [],
      "source": [
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d479743",
      "metadata": {
        "id": "0d479743"
      },
      "outputs": [],
      "source": [
        "START_EPOCH = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8ec40e9",
      "metadata": {
        "id": "c8ec40e9"
      },
      "source": [
        "### Set the architecture to resnet 18 below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97b1a0aa",
      "metadata": {
        "tags": [
          "parameters"
        ],
        "id": "97b1a0aa"
      },
      "outputs": [],
      "source": [
        "##########################\n",
        "ARCH = \"resnet18\"\n",
        "# set the architecture to RESNET 18\n",
        "# please look up how to do that\n",
        "########################\n",
        "EPOCHS = 20\n",
        "LR = 0.1\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 5e-4\n",
        "PRINT_FREQ = 50\n",
        "TRAIN_BATCH=128\n",
        "VAL_BATCH=128\n",
        "WORKERS=2\n",
        "# TRAINDIR=\"/workspace/data/imagenet2012/train\"\n",
        "# VALDIR=\"/workspace/data/imagenet2012/val\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09de23aa",
      "metadata": {
        "id": "09de23aa"
      },
      "outputs": [],
      "source": [
        "# TRAINDIR=\"/CINIC/train\"\n",
        "# VALDIR=\"/CINIC/valid\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e86c3188",
      "metadata": {
        "id": "e86c3188"
      },
      "source": [
        "### Check if cuda is available here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63a0499b",
      "metadata": {
        "id": "63a0499b",
        "outputId": "fedd84db-203f-4f4b-a19c-d96c478137da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# check if cuda is available in this cell\n",
        "# if it is not available, you should not go forward!\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f83c35f6",
      "metadata": {
        "id": "f83c35f6"
      },
      "source": [
        "### Assign your GPU below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "252a08a3",
      "metadata": {
        "id": "252a08a3"
      },
      "outputs": [],
      "source": [
        "# Assign your GPU in this cell\n",
        "GPU = torch.cuda.current_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8e7ec23",
      "metadata": {
        "id": "d8e7ec23",
        "outputId": "d560ff0a-d750-4dfa-94ba-369fa40c0ce5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# set your active device to your GPU in this cell\n",
        "device = torch.device('cuda:0')\n",
        "\n",
        "device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e5ddf20",
      "metadata": {
        "id": "1e5ddf20"
      },
      "outputs": [],
      "source": [
        "# enable algorithm optimization\n",
        "cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cdd6e12",
      "metadata": {
        "id": "7cdd6e12"
      },
      "source": [
        "### Fill in the heart of the train section below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70dbd4c4",
      "metadata": {
        "id": "70dbd4c4"
      },
      "outputs": [],
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    data_time = AverageMeter('Data', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    progress = ProgressMeter(\n",
        "        len(train_loader),\n",
        "        [batch_time, data_time, losses, top1, top5],\n",
        "        prefix=\"Epoch: [{}]\".format(epoch))\n",
        "\n",
        "    ######################\n",
        "    # switch mo(del to train mode here\n",
        "    model.train()\n",
        "    ################\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (images, target) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        #####################\n",
        "        # send the images to cuda device\n",
        "        # send the target to cuda device\n",
        "        images = images.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "\n",
        "        # compute output\n",
        "        output = model(images)\n",
        "\n",
        "        # compute loss \n",
        "        loss = criterion(output, target)\n",
        "\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        losses.update(loss.item(), images.size(0))\n",
        "        top1.update(acc1[0], images.size(0))\n",
        "        top5.update(acc5[0], images.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        \n",
        "        #### zero out gradients in the optimier\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        ## backprop!\n",
        "        loss.backward()\n",
        "        \n",
        "        # update the weights!\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % PRINT_FREQ == 0:\n",
        "            progress.display(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "deb3b62e",
      "metadata": {
        "id": "deb3b62e"
      },
      "source": [
        "#### Fill in the validate section below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3f276cc",
      "metadata": {
        "id": "a3f276cc"
      },
      "outputs": [],
      "source": [
        "\n",
        "def validate(val_loader, model, criterion):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    progress = ProgressMeter(\n",
        "        len(val_loader),\n",
        "        [batch_time, losses, top1, top5],\n",
        "        prefix='Test: ')\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        end = time.time()\n",
        "        for i, (images, target) in enumerate(val_loader):\n",
        "            \n",
        "            \n",
        "            ### send the images and target to cuda\n",
        "            images = images.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            # compute output\n",
        "            output = model(images)\n",
        "\n",
        "            # compute loss\n",
        "            loss  = criterion(output, target)\n",
        "\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "            losses.update(loss.item(), images.size(0))\n",
        "            top1.update(acc1[0], images.size(0))\n",
        "            top5.update(acc5[0], images.size(0))\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "            if i % PRINT_FREQ == 0:\n",
        "                progress.display(i)\n",
        "\n",
        "        # TODO: this should also be done with the ProgressMeter\n",
        "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
        "              .format(top1=top1, top5=top5))\n",
        "\n",
        "    return top1.avg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbe49226",
      "metadata": {
        "id": "fbe49226"
      },
      "source": [
        "### Save the checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff8a4159",
      "metadata": {
        "id": "ff8a4159"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    # save the model state!\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, 'model_best.pth.tar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cd7ea3a",
      "metadata": {
        "id": "1cd7ea3a"
      },
      "outputs": [],
      "source": [
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1da87ab",
      "metadata": {
        "id": "e1da87ab"
      },
      "outputs": [],
      "source": [
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def display(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00211030",
      "metadata": {
        "id": "00211030"
      },
      "outputs": [],
      "source": [
        "# if we are adjusting the LR manually use this\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    lr = LR * (0.1 ** (epoch // 30))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da2c1382",
      "metadata": {
        "id": "da2c1382"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c29e7a1",
      "metadata": {
        "id": "5c29e7a1"
      },
      "outputs": [],
      "source": [
        "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
        "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
        "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
        "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
        "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
        "cifar_std_RGB = [0.2023, 0.1994, 0.2010]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1a61c02",
      "metadata": {
        "id": "e1a61c02"
      },
      "outputs": [],
      "source": [
        "normalize = transforms.Normalize(mean=cifar_mean_RGB, std=cifar_std_RGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47dd3e49",
      "metadata": {
        "id": "47dd3e49"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 32\n",
        "# IMG_SIZE = 224\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de4387cb",
      "metadata": {
        "id": "de4387cb"
      },
      "source": [
        "### Initialize the model using the architecture you selected above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1abcc33",
      "metadata": {
        "id": "b1abcc33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee389eca-3d25-45de-d9f7-61d98a672f24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# select the model\n",
        "if ARCH == \"resnet18\":\n",
        "    model = models.resnet18(pretrained=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2db1bb69",
      "metadata": {
        "id": "2db1bb69"
      },
      "source": [
        "### Send the model to the cuda device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d23ccb4",
      "metadata": {
        "id": "7d23ccb4"
      },
      "outputs": [],
      "source": [
        "# send the model to the cuda device.. \n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47a8eb8d",
      "metadata": {
        "id": "47a8eb8d"
      },
      "source": [
        "### Instantiate the loss to cross entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a49ae3c9",
      "metadata": {
        "id": "a49ae3c9"
      },
      "outputs": [],
      "source": [
        "# use the cross-entropy loss\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a49045a",
      "metadata": {
        "id": "8a49045a"
      },
      "source": [
        "### Instantiate the optimizer to SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa3a04dd",
      "metadata": {
        "id": "aa3a04dd"
      },
      "outputs": [],
      "source": [
        "# use SGD .. use the momentum and weight decay vars\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f93ef11d",
      "metadata": {
        "id": "f93ef11d"
      },
      "source": [
        "#### Create the learning rate scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0e1727a",
      "metadata": {
        "id": "a0e1727a"
      },
      "outputs": [],
      "source": [
        "# use CosineAnnealingLR\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fe08caa",
      "metadata": {
        "id": "2fe08caa"
      },
      "outputs": [],
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cifar_mean_RGB, cifar_std_RGB),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "236528e1",
      "metadata": {
        "id": "236528e1"
      },
      "source": [
        "### Create the train dataset object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c29f6b1",
      "metadata": {
        "id": "7c29f6b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "260d5e72-e101-441d-da09-0b18858df5ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# use torchvision.datasets.CIFAR10\n",
        "train_dataset = torchvision.datasets.CIFAR10('./datasets', train=True, \n",
        "                                         download=True, transform=transform_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63dfe3c0",
      "metadata": {
        "id": "63dfe3c0"
      },
      "outputs": [],
      "source": [
        "transform_val = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cifar_mean_RGB, cifar_std_RGB),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38ca6c39",
      "metadata": {
        "id": "38ca6c39"
      },
      "source": [
        "### Create the val dataset object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42d58f82",
      "metadata": {
        "id": "42d58f82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df54258c-6eec-4bff-f598-152b2a003363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# use torchvision.datasets.CIFAR10\n",
        "val_dataset = torchvision.datasets.CIFAR10(root='./datasets', train=False,\n",
        "                                        download=True, transform=transform_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a291660",
      "metadata": {
        "id": "3a291660"
      },
      "source": [
        "### Create the train dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "574373be",
      "metadata": {
        "id": "574373be"
      },
      "outputs": [],
      "source": [
        "# fill this in\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=TRAIN_BATCH, \n",
        "                                           shuffle=True, num_workers=WORKERS)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b280c6e0",
      "metadata": {
        "id": "b280c6e0"
      },
      "source": [
        "### Create the c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aa623fe",
      "metadata": {
        "id": "6aa623fe"
      },
      "outputs": [],
      "source": [
        "# fill this in..\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=VAL_BATCH, \n",
        "                                          shuffle=False, num_workers=WORKERS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cfa6766",
      "metadata": {
        "id": "7cfa6766"
      },
      "outputs": [],
      "source": [
        "best_acc1 = 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kz9RQ5pHyQBg"
      },
      "id": "kz9RQ5pHyQBg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d0620a6",
      "metadata": {
        "id": "0d0620a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "890f8db5-f1bb-4f5f-9059-bd3709626e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][  0/391]\tTime  3.249 ( 3.249)\tData  0.181 ( 0.181)\tLoss 1.4050e+01 (1.4050e+01)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
            "Epoch: [0][ 50/391]\tTime  0.030 ( 0.114)\tData  0.001 ( 0.032)\tLoss 2.6908e+00 (4.1772e+00)\tAcc@1   9.38 ( 11.00)\tAcc@5  55.47 ( 50.51)\n",
            "Epoch: [0][100/391]\tTime  0.050 ( 0.083)\tData  0.032 ( 0.029)\tLoss 2.2480e+00 (3.3649e+00)\tAcc@1  18.75 ( 13.27)\tAcc@5  65.62 ( 56.43)\n",
            "Epoch: [0][150/391]\tTime  0.098 ( 0.077)\tData  0.073 ( 0.033)\tLoss 2.0876e+00 (3.0269e+00)\tAcc@1  15.62 ( 14.95)\tAcc@5  78.12 ( 61.96)\n",
            "Epoch: [0][200/391]\tTime  0.022 ( 0.072)\tData  0.001 ( 0.032)\tLoss 2.0611e+00 (2.8155e+00)\tAcc@1  19.53 ( 16.41)\tAcc@5  83.59 ( 66.12)\n",
            "Epoch: [0][250/391]\tTime  0.082 ( 0.068)\tData  0.059 ( 0.031)\tLoss 1.9450e+00 (2.6654e+00)\tAcc@1  31.25 ( 18.02)\tAcc@5  83.59 ( 68.96)\n",
            "Epoch: [0][300/391]\tTime  0.052 ( 0.065)\tData  0.027 ( 0.031)\tLoss 1.8591e+00 (2.5577e+00)\tAcc@1  33.59 ( 18.93)\tAcc@5  84.38 ( 70.90)\n",
            "Epoch: [0][350/391]\tTime  0.054 ( 0.063)\tData  0.032 ( 0.030)\tLoss 2.6827e+00 (2.4765e+00)\tAcc@1   9.38 ( 19.75)\tAcc@5  54.69 ( 72.57)\n",
            "Test: [ 0/79]\tTime  0.170 ( 0.170)\tLoss 2.1399e+00 (2.1399e+00)\tAcc@1  24.22 ( 24.22)\tAcc@5  66.41 ( 66.41)\n",
            "Test: [50/79]\tTime  0.036 ( 0.038)\tLoss 2.2201e+00 (2.3039e+00)\tAcc@1  22.66 ( 16.93)\tAcc@5  69.53 ( 66.82)\n",
            " * Acc@1 17.330 Acc@5 67.060\n",
            "lr: [0.09997532801828658]\n",
            "Epoch: [1][  0/391]\tTime  0.276 ( 0.276)\tData  0.231 ( 0.231)\tLoss 2.1857e+00 (2.1857e+00)\tAcc@1  16.41 ( 16.41)\tAcc@5  71.09 ( 71.09)\n",
            "Epoch: [1][ 50/391]\tTime  0.063 ( 0.058)\tData  0.047 ( 0.034)\tLoss 2.1084e+00 (2.1639e+00)\tAcc@1  21.88 ( 18.17)\tAcc@5  75.00 ( 69.98)\n",
            "Epoch: [1][100/391]\tTime  0.071 ( 0.054)\tData  0.053 ( 0.031)\tLoss 1.9295e+00 (2.0951e+00)\tAcc@1  27.34 ( 19.95)\tAcc@5  77.34 ( 74.25)\n",
            "Epoch: [1][150/391]\tTime  0.059 ( 0.059)\tData  0.035 ( 0.036)\tLoss 2.0181e+00 (2.0358e+00)\tAcc@1  21.88 ( 22.44)\tAcc@5  75.78 ( 77.06)\n",
            "Epoch: [1][200/391]\tTime  0.085 ( 0.057)\tData  0.069 ( 0.034)\tLoss 1.8111e+00 (1.9891e+00)\tAcc@1  32.81 ( 23.88)\tAcc@5  84.38 ( 78.84)\n",
            "Epoch: [1][250/391]\tTime  0.076 ( 0.055)\tData  0.061 ( 0.033)\tLoss 1.7419e+00 (1.9534e+00)\tAcc@1  29.69 ( 25.31)\tAcc@5  88.28 ( 80.05)\n",
            "Epoch: [1][300/391]\tTime  0.066 ( 0.055)\tData  0.043 ( 0.032)\tLoss 1.6482e+00 (1.9165e+00)\tAcc@1  37.50 ( 26.80)\tAcc@5  89.84 ( 81.18)\n",
            "Epoch: [1][350/391]\tTime  0.104 ( 0.054)\tData  0.075 ( 0.031)\tLoss 1.7311e+00 (1.8838e+00)\tAcc@1  38.28 ( 28.26)\tAcc@5  87.50 ( 82.11)\n",
            "Test: [ 0/79]\tTime  0.182 ( 0.182)\tLoss 1.5808e+00 (1.5808e+00)\tAcc@1  42.19 ( 42.19)\tAcc@5  91.41 ( 91.41)\n",
            "Test: [50/79]\tTime  0.053 ( 0.038)\tLoss 1.8373e+00 (1.6140e+00)\tAcc@1  35.16 ( 40.53)\tAcc@5  82.03 ( 88.68)\n",
            " * Acc@1 40.530 Acc@5 88.610\n",
            "lr: [0.09990133642141358]\n",
            "Epoch: [2][  0/391]\tTime  0.426 ( 0.426)\tData  0.399 ( 0.399)\tLoss 1.6637e+00 (1.6637e+00)\tAcc@1  39.06 ( 39.06)\tAcc@5  90.62 ( 90.62)\n",
            "Epoch: [2][ 50/391]\tTime  0.036 ( 0.057)\tData  0.020 ( 0.033)\tLoss 1.6324e+00 (1.6336e+00)\tAcc@1  38.28 ( 38.94)\tAcc@5  88.28 ( 89.28)\n",
            "Epoch: [2][100/391]\tTime  0.066 ( 0.054)\tData  0.051 ( 0.030)\tLoss 1.8491e+00 (1.6269e+00)\tAcc@1  35.16 ( 39.50)\tAcc@5  82.81 ( 89.19)\n",
            "Epoch: [2][150/391]\tTime  0.083 ( 0.059)\tData  0.051 ( 0.035)\tLoss 1.4905e+00 (1.6256e+00)\tAcc@1  50.78 ( 39.84)\tAcc@5  91.41 ( 89.38)\n",
            "Epoch: [2][200/391]\tTime  0.077 ( 0.058)\tData  0.060 ( 0.033)\tLoss 1.4463e+00 (1.6128e+00)\tAcc@1  50.00 ( 40.08)\tAcc@5  91.41 ( 89.55)\n",
            "Epoch: [2][250/391]\tTime  0.033 ( 0.056)\tData  0.001 ( 0.032)\tLoss 1.3666e+00 (1.5947e+00)\tAcc@1  49.22 ( 40.85)\tAcc@5  92.19 ( 89.87)\n",
            "Epoch: [2][300/391]\tTime  0.039 ( 0.055)\tData  0.001 ( 0.031)\tLoss 1.5472e+00 (1.5834e+00)\tAcc@1  42.19 ( 41.27)\tAcc@5  89.06 ( 90.07)\n",
            "Epoch: [2][350/391]\tTime  0.153 ( 0.056)\tData  0.117 ( 0.031)\tLoss 1.4389e+00 (1.5739e+00)\tAcc@1  50.00 ( 41.73)\tAcc@5  92.97 ( 90.25)\n",
            "Test: [ 0/79]\tTime  0.391 ( 0.391)\tLoss 1.2713e+00 (1.2713e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  93.75 ( 93.75)\n",
            "Test: [50/79]\tTime  0.011 ( 0.040)\tLoss 1.4852e+00 (1.4502e+00)\tAcc@1  43.75 ( 47.86)\tAcc@5  91.41 ( 93.09)\n",
            " * Acc@1 47.730 Acc@5 92.860\n",
            "lr: [0.099778098230154]\n",
            "Epoch: [3][  0/391]\tTime  0.257 ( 0.257)\tData  0.210 ( 0.210)\tLoss 1.3045e+00 (1.3045e+00)\tAcc@1  50.00 ( 50.00)\tAcc@5  94.53 ( 94.53)\n",
            "Epoch: [3][ 50/391]\tTime  0.068 ( 0.055)\tData  0.052 ( 0.030)\tLoss 1.3446e+00 (1.4629e+00)\tAcc@1  46.88 ( 46.12)\tAcc@5  94.53 ( 92.60)\n",
            "Epoch: [3][100/391]\tTime  0.030 ( 0.052)\tData  0.008 ( 0.028)\tLoss 1.5685e+00 (1.4483e+00)\tAcc@1  47.66 ( 47.13)\tAcc@5  91.41 ( 92.38)\n",
            "Epoch: [3][150/391]\tTime  0.036 ( 0.058)\tData  0.001 ( 0.033)\tLoss 1.4253e+00 (1.4456e+00)\tAcc@1  48.44 ( 47.05)\tAcc@5  89.84 ( 92.51)\n",
            "Epoch: [3][200/391]\tTime  0.039 ( 0.056)\tData  0.017 ( 0.031)\tLoss 1.8598e+00 (1.5141e+00)\tAcc@1  32.03 ( 44.66)\tAcc@5  82.03 ( 91.07)\n",
            "Epoch: [3][250/391]\tTime  0.095 ( 0.055)\tData  0.066 ( 0.030)\tLoss 1.6254e+00 (1.5628e+00)\tAcc@1  36.72 ( 42.70)\tAcc@5  87.50 ( 90.16)\n",
            "Epoch: [3][300/391]\tTime  0.038 ( 0.054)\tData  0.022 ( 0.030)\tLoss 1.5460e+00 (1.5759e+00)\tAcc@1  40.62 ( 42.12)\tAcc@5  89.84 ( 90.01)\n",
            "Epoch: [3][350/391]\tTime  0.035 ( 0.054)\tData  0.000 ( 0.030)\tLoss 1.5763e+00 (1.5788e+00)\tAcc@1  42.97 ( 42.13)\tAcc@5  89.84 ( 89.96)\n",
            "Test: [ 0/79]\tTime  0.172 ( 0.172)\tLoss 1.4572e+00 (1.4572e+00)\tAcc@1  46.88 ( 46.88)\tAcc@5  92.97 ( 92.97)\n",
            "Test: [50/79]\tTime  0.025 ( 0.034)\tLoss 1.6103e+00 (1.4874e+00)\tAcc@1  35.94 ( 45.33)\tAcc@5  92.19 ( 92.25)\n",
            " * Acc@1 44.690 Acc@5 91.890\n",
            "lr: [0.0996057350657239]\n",
            "Epoch: [4][  0/391]\tTime  0.233 ( 0.233)\tData  0.200 ( 0.200)\tLoss 1.5630e+00 (1.5630e+00)\tAcc@1  40.62 ( 40.62)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [4][ 50/391]\tTime  0.027 ( 0.054)\tData  0.005 ( 0.030)\tLoss 1.5814e+00 (1.5440e+00)\tAcc@1  41.41 ( 43.57)\tAcc@5  89.84 ( 91.21)\n",
            "Epoch: [4][100/391]\tTime  0.063 ( 0.053)\tData  0.040 ( 0.029)\tLoss 1.4791e+00 (1.4987e+00)\tAcc@1  42.97 ( 44.65)\tAcc@5  92.19 ( 91.96)\n",
            "Epoch: [4][150/391]\tTime  0.047 ( 0.057)\tData  0.006 ( 0.033)\tLoss 1.4073e+00 (1.4856e+00)\tAcc@1  48.44 ( 45.36)\tAcc@5  92.97 ( 92.03)\n",
            "Epoch: [4][200/391]\tTime  0.061 ( 0.057)\tData  0.039 ( 0.032)\tLoss 1.5571e+00 (1.4722e+00)\tAcc@1  40.62 ( 45.87)\tAcc@5  90.62 ( 92.20)\n",
            "Epoch: [4][250/391]\tTime  0.042 ( 0.055)\tData  0.021 ( 0.031)\tLoss 1.3658e+00 (1.4573e+00)\tAcc@1  46.88 ( 46.42)\tAcc@5  92.97 ( 92.38)\n",
            "Epoch: [4][300/391]\tTime  0.038 ( 0.055)\tData  0.001 ( 0.030)\tLoss 1.4961e+00 (1.4417e+00)\tAcc@1  46.88 ( 47.06)\tAcc@5  92.97 ( 92.61)\n",
            "Epoch: [4][350/391]\tTime  0.058 ( 0.054)\tData  0.037 ( 0.030)\tLoss 1.3023e+00 (1.4309e+00)\tAcc@1  49.22 ( 47.61)\tAcc@5  91.41 ( 92.65)\n",
            "Test: [ 0/79]\tTime  0.168 ( 0.168)\tLoss 1.3442e+00 (1.3442e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  92.97 ( 92.97)\n",
            "Test: [50/79]\tTime  0.020 ( 0.034)\tLoss 1.4894e+00 (1.4308e+00)\tAcc@1  46.88 ( 48.74)\tAcc@5  92.19 ( 93.54)\n",
            " * Acc@1 48.680 Acc@5 93.480\n",
            "lr: [0.09938441702975688]\n",
            "Epoch: [5][  0/391]\tTime  0.457 ( 0.457)\tData  0.365 ( 0.365)\tLoss 1.2599e+00 (1.2599e+00)\tAcc@1  53.91 ( 53.91)\tAcc@5  96.09 ( 96.09)\n",
            "Epoch: [5][ 50/391]\tTime  0.071 ( 0.074)\tData  0.047 ( 0.043)\tLoss 1.2829e+00 (1.3393e+00)\tAcc@1  57.03 ( 51.50)\tAcc@5  92.97 ( 93.93)\n",
            "Epoch: [5][100/391]\tTime  0.062 ( 0.064)\tData  0.039 ( 0.036)\tLoss 1.3412e+00 (1.3258e+00)\tAcc@1  54.69 ( 51.81)\tAcc@5  91.41 ( 93.86)\n",
            "Epoch: [5][150/391]\tTime  0.092 ( 0.068)\tData  0.076 ( 0.039)\tLoss 1.3845e+00 (1.3125e+00)\tAcc@1  51.56 ( 52.48)\tAcc@5  95.31 ( 94.02)\n",
            "Epoch: [5][200/391]\tTime  0.035 ( 0.064)\tData  0.001 ( 0.036)\tLoss 1.0834e+00 (1.3046e+00)\tAcc@1  60.94 ( 52.70)\tAcc@5  97.66 ( 94.13)\n",
            "Epoch: [5][250/391]\tTime  0.062 ( 0.061)\tData  0.046 ( 0.034)\tLoss 1.2429e+00 (1.2966e+00)\tAcc@1  53.12 ( 53.08)\tAcc@5  94.53 ( 94.13)\n",
            "Epoch: [5][300/391]\tTime  0.067 ( 0.059)\tData  0.049 ( 0.034)\tLoss 1.3833e+00 (1.2921e+00)\tAcc@1  53.12 ( 53.39)\tAcc@5  93.75 ( 94.24)\n",
            "Epoch: [5][350/391]\tTime  0.080 ( 0.059)\tData  0.058 ( 0.034)\tLoss 1.2531e+00 (1.2871e+00)\tAcc@1  56.25 ( 53.51)\tAcc@5  94.53 ( 94.30)\n",
            "Test: [ 0/79]\tTime  0.178 ( 0.178)\tLoss 1.1651e+00 (1.1651e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  96.88 ( 96.88)\n",
            "Test: [50/79]\tTime  0.021 ( 0.036)\tLoss 1.2624e+00 (1.2204e+00)\tAcc@1  57.81 ( 57.69)\tAcc@5  93.75 ( 94.61)\n",
            " * Acc@1 57.630 Acc@5 94.650\n",
            "lr: [0.09911436253643444]\n",
            "Epoch: [6][  0/391]\tTime  0.257 ( 0.257)\tData  0.214 ( 0.214)\tLoss 1.0537e+00 (1.0537e+00)\tAcc@1  64.84 ( 64.84)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [6][ 50/391]\tTime  0.027 ( 0.053)\tData  0.004 ( 0.028)\tLoss 1.2585e+00 (1.2097e+00)\tAcc@1  56.25 ( 56.62)\tAcc@5  94.53 ( 95.10)\n",
            "Epoch: [6][100/391]\tTime  0.027 ( 0.052)\tData  0.006 ( 0.028)\tLoss 1.3187e+00 (1.2004e+00)\tAcc@1  53.91 ( 56.88)\tAcc@5  93.75 ( 95.10)\n",
            "Epoch: [6][150/391]\tTime  0.040 ( 0.059)\tData  0.001 ( 0.032)\tLoss 1.1099e+00 (1.1954e+00)\tAcc@1  58.59 ( 56.99)\tAcc@5  94.53 ( 95.23)\n",
            "Epoch: [6][200/391]\tTime  0.056 ( 0.056)\tData  0.035 ( 0.030)\tLoss 9.5179e-01 (1.1819e+00)\tAcc@1  67.19 ( 57.57)\tAcc@5  94.53 ( 95.38)\n",
            "Epoch: [6][250/391]\tTime  0.077 ( 0.055)\tData  0.055 ( 0.030)\tLoss 1.2001e+00 (1.1746e+00)\tAcc@1  59.38 ( 57.90)\tAcc@5  96.88 ( 95.41)\n",
            "Epoch: [6][300/391]\tTime  0.060 ( 0.055)\tData  0.044 ( 0.030)\tLoss 1.2185e+00 (1.1695e+00)\tAcc@1  53.91 ( 58.05)\tAcc@5  94.53 ( 95.47)\n",
            "Epoch: [6][350/391]\tTime  0.136 ( 0.055)\tData  0.117 ( 0.030)\tLoss 1.1246e+00 (1.1644e+00)\tAcc@1  58.59 ( 58.21)\tAcc@5  96.09 ( 95.54)\n",
            "Test: [ 0/79]\tTime  0.190 ( 0.190)\tLoss 9.1060e-01 (9.1060e-01)\tAcc@1  70.31 ( 70.31)\tAcc@5  97.66 ( 97.66)\n",
            "Test: [50/79]\tTime  0.040 ( 0.035)\tLoss 9.6808e-01 (1.0695e+00)\tAcc@1  66.41 ( 62.48)\tAcc@5  95.31 ( 96.35)\n",
            " * Acc@1 62.170 Acc@5 96.410\n",
            "lr: [0.09879583809693737]\n",
            "Epoch: [7][  0/391]\tTime  0.264 ( 0.264)\tData  0.223 ( 0.223)\tLoss 1.1930e+00 (1.1930e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [7][ 50/391]\tTime  0.031 ( 0.056)\tData  0.001 ( 0.031)\tLoss 1.0641e+00 (1.1184e+00)\tAcc@1  61.72 ( 59.48)\tAcc@5  96.09 ( 96.00)\n",
            "Epoch: [7][100/391]\tTime  0.028 ( 0.053)\tData  0.001 ( 0.028)\tLoss 1.0649e+00 (1.1155e+00)\tAcc@1  60.94 ( 60.02)\tAcc@5  98.44 ( 96.03)\n",
            "Epoch: [7][150/391]\tTime  0.126 ( 0.059)\tData  0.095 ( 0.033)\tLoss 1.0920e+00 (1.1156e+00)\tAcc@1  61.72 ( 60.19)\tAcc@5  98.44 ( 96.08)\n",
            "Epoch: [7][200/391]\tTime  0.051 ( 0.058)\tData  0.029 ( 0.032)\tLoss 1.1898e+00 (1.1128e+00)\tAcc@1  53.91 ( 60.23)\tAcc@5  97.66 ( 96.08)\n",
            "Epoch: [7][250/391]\tTime  0.054 ( 0.056)\tData  0.036 ( 0.031)\tLoss 1.0683e+00 (1.1088e+00)\tAcc@1  66.41 ( 60.42)\tAcc@5  96.09 ( 96.04)\n",
            "Epoch: [7][300/391]\tTime  0.046 ( 0.055)\tData  0.031 ( 0.031)\tLoss 1.0832e+00 (1.1046e+00)\tAcc@1  62.50 ( 60.74)\tAcc@5  96.88 ( 96.14)\n",
            "Epoch: [7][350/391]\tTime  0.085 ( 0.055)\tData  0.061 ( 0.031)\tLoss 9.2897e-01 (1.1005e+00)\tAcc@1  64.84 ( 60.92)\tAcc@5  98.44 ( 96.14)\n",
            "Test: [ 0/79]\tTime  0.183 ( 0.183)\tLoss 1.1229e+00 (1.1229e+00)\tAcc@1  67.19 ( 67.19)\tAcc@5  96.09 ( 96.09)\n",
            "Test: [50/79]\tTime  0.056 ( 0.036)\tLoss 1.1698e+00 (1.2187e+00)\tAcc@1  64.84 ( 58.69)\tAcc@5  93.75 ( 95.93)\n",
            " * Acc@1 58.730 Acc@5 95.980\n",
            "lr: [0.09842915805643156]\n",
            "Epoch: [8][  0/391]\tTime  0.259 ( 0.259)\tData  0.204 ( 0.204)\tLoss 1.2990e+00 (1.2990e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [8][ 50/391]\tTime  0.034 ( 0.055)\tData  0.001 ( 0.030)\tLoss 9.9289e-01 (1.0495e+00)\tAcc@1  64.84 ( 63.19)\tAcc@5  99.22 ( 96.54)\n",
            "Epoch: [8][100/391]\tTime  0.034 ( 0.053)\tData  0.001 ( 0.028)\tLoss 1.1375e+00 (1.0471e+00)\tAcc@1  60.16 ( 63.23)\tAcc@5  95.31 ( 96.47)\n",
            "Epoch: [8][150/391]\tTime  0.152 ( 0.058)\tData  0.125 ( 0.032)\tLoss 1.1568e+00 (1.0412e+00)\tAcc@1  64.06 ( 63.36)\tAcc@5  92.97 ( 96.44)\n",
            "Epoch: [8][200/391]\tTime  0.037 ( 0.057)\tData  0.001 ( 0.032)\tLoss 1.0331e+00 (1.0465e+00)\tAcc@1  63.28 ( 63.24)\tAcc@5  97.66 ( 96.40)\n",
            "Epoch: [8][250/391]\tTime  0.026 ( 0.056)\tData  0.000 ( 0.031)\tLoss 9.1258e-01 (1.0446e+00)\tAcc@1  65.62 ( 63.25)\tAcc@5  96.09 ( 96.39)\n",
            "Epoch: [8][300/391]\tTime  0.063 ( 0.055)\tData  0.043 ( 0.031)\tLoss 1.0977e+00 (1.0465e+00)\tAcc@1  58.59 ( 63.16)\tAcc@5  95.31 ( 96.41)\n",
            "Epoch: [8][350/391]\tTime  0.042 ( 0.054)\tData  0.019 ( 0.031)\tLoss 1.0761e+00 (1.0459e+00)\tAcc@1  60.94 ( 63.15)\tAcc@5  96.88 ( 96.44)\n",
            "Test: [ 0/79]\tTime  0.199 ( 0.199)\tLoss 1.0961e+00 (1.0961e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  99.22 ( 99.22)\n",
            "Test: [50/79]\tTime  0.021 ( 0.037)\tLoss 1.0753e+00 (1.1341e+00)\tAcc@1  63.28 ( 61.01)\tAcc@5  94.53 ( 96.83)\n",
            " * Acc@1 60.850 Acc@5 96.800\n",
            "lr: [0.09801468428384716]\n",
            "Epoch: [9][  0/391]\tTime  0.247 ( 0.247)\tData  0.204 ( 0.204)\tLoss 1.1409e+00 (1.1409e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [9][ 50/391]\tTime  0.026 ( 0.055)\tData  0.009 ( 0.030)\tLoss 1.0180e+00 (1.0196e+00)\tAcc@1  64.84 ( 63.45)\tAcc@5  96.09 ( 97.14)\n",
            "Epoch: [9][100/391]\tTime  0.038 ( 0.053)\tData  0.023 ( 0.029)\tLoss 9.4785e-01 (1.0105e+00)\tAcc@1  65.62 ( 64.35)\tAcc@5  96.88 ( 97.07)\n",
            "Epoch: [9][150/391]\tTime  0.106 ( 0.056)\tData  0.066 ( 0.030)\tLoss 1.0017e+00 (1.0129e+00)\tAcc@1  64.84 ( 64.09)\tAcc@5  96.88 ( 96.93)\n",
            "Epoch: [9][200/391]\tTime  0.072 ( 0.057)\tData  0.048 ( 0.031)\tLoss 1.1294e+00 (1.0182e+00)\tAcc@1  57.81 ( 63.81)\tAcc@5  98.44 ( 96.85)\n",
            "Epoch: [9][250/391]\tTime  0.068 ( 0.056)\tData  0.052 ( 0.031)\tLoss 1.1102e+00 (1.0177e+00)\tAcc@1  63.28 ( 63.99)\tAcc@5  95.31 ( 96.69)\n",
            "Epoch: [9][300/391]\tTime  0.062 ( 0.055)\tData  0.040 ( 0.031)\tLoss 8.8289e-01 (1.0159e+00)\tAcc@1  68.75 ( 64.14)\tAcc@5  97.66 ( 96.68)\n",
            "Epoch: [9][350/391]\tTime  0.030 ( 0.054)\tData  0.001 ( 0.031)\tLoss 8.6216e-01 (1.0101e+00)\tAcc@1  67.19 ( 64.38)\tAcc@5  98.44 ( 96.69)\n",
            "Test: [ 0/79]\tTime  0.286 ( 0.286)\tLoss 8.5752e-01 (8.5752e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5  97.66 ( 97.66)\n",
            "Test: [50/79]\tTime  0.016 ( 0.041)\tLoss 9.5956e-01 (9.3077e-01)\tAcc@1  71.88 ( 67.72)\tAcc@5  96.09 ( 97.17)\n",
            " * Acc@1 67.340 Acc@5 97.300\n",
            "lr: [0.09755282581475769]\n",
            "Epoch: [10][  0/391]\tTime  0.260 ( 0.260)\tData  0.221 ( 0.221)\tLoss 9.6093e-01 (9.6093e-01)\tAcc@1  67.97 ( 67.97)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [10][ 50/391]\tTime  0.078 ( 0.056)\tData  0.057 ( 0.032)\tLoss 9.7332e-01 (9.6429e-01)\tAcc@1  67.19 ( 66.56)\tAcc@5  96.88 ( 97.14)\n",
            "Epoch: [10][100/391]\tTime  0.021 ( 0.054)\tData  0.006 ( 0.031)\tLoss 8.8233e-01 (9.7272e-01)\tAcc@1  65.62 ( 65.85)\tAcc@5  97.66 ( 97.11)\n",
            "Epoch: [10][150/391]\tTime  0.130 ( 0.055)\tData  0.116 ( 0.031)\tLoss 1.0536e+00 (9.6962e-01)\tAcc@1  64.06 ( 65.98)\tAcc@5  97.66 ( 97.01)\n",
            "Epoch: [10][200/391]\tTime  0.023 ( 0.058)\tData  0.001 ( 0.033)\tLoss 9.7513e-01 (9.6676e-01)\tAcc@1  66.41 ( 66.26)\tAcc@5  97.66 ( 97.07)\n",
            "Epoch: [10][250/391]\tTime  0.023 ( 0.056)\tData  0.001 ( 0.033)\tLoss 1.0095e+00 (9.6878e-01)\tAcc@1  65.62 ( 66.10)\tAcc@5  96.09 ( 97.12)\n",
            "Epoch: [10][300/391]\tTime  0.032 ( 0.055)\tData  0.007 ( 0.032)\tLoss 9.8916e-01 (9.6887e-01)\tAcc@1  67.19 ( 66.18)\tAcc@5  97.66 ( 97.09)\n",
            "Epoch: [10][350/391]\tTime  0.022 ( 0.055)\tData  0.004 ( 0.032)\tLoss 8.1100e-01 (9.6727e-01)\tAcc@1  67.19 ( 66.24)\tAcc@5  97.66 ( 97.06)\n",
            "Test: [ 0/79]\tTime  0.357 ( 0.357)\tLoss 9.1185e-01 (9.1185e-01)\tAcc@1  68.75 ( 68.75)\tAcc@5  98.44 ( 98.44)\n",
            "Test: [50/79]\tTime  0.017 ( 0.059)\tLoss 1.0574e+00 (1.0947e+00)\tAcc@1  69.53 ( 62.29)\tAcc@5  96.09 ( 96.43)\n",
            " * Acc@1 62.130 Acc@5 96.330\n",
            "lr: [0.09704403844771128]\n",
            "Epoch: [11][  0/391]\tTime  0.241 ( 0.241)\tData  0.205 ( 0.205)\tLoss 9.8461e-01 (9.8461e-01)\tAcc@1  64.84 ( 64.84)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [11][ 50/391]\tTime  0.080 ( 0.056)\tData  0.057 ( 0.032)\tLoss 1.0448e+00 (9.4267e-01)\tAcc@1  67.19 ( 67.20)\tAcc@5  94.53 ( 97.01)\n",
            "Epoch: [11][100/391]\tTime  0.036 ( 0.053)\tData  0.007 ( 0.029)\tLoss 1.1222e+00 (9.4596e-01)\tAcc@1  62.50 ( 66.88)\tAcc@5  95.31 ( 97.09)\n",
            "Epoch: [11][150/391]\tTime  0.038 ( 0.053)\tData  0.015 ( 0.029)\tLoss 9.1072e-01 (9.3850e-01)\tAcc@1  64.06 ( 67.16)\tAcc@5  97.66 ( 97.22)\n",
            "Epoch: [11][200/391]\tTime  0.086 ( 0.058)\tData  0.060 ( 0.032)\tLoss 9.6374e-01 (9.3318e-01)\tAcc@1  71.09 ( 67.32)\tAcc@5  97.66 ( 97.24)\n",
            "Epoch: [11][250/391]\tTime  0.071 ( 0.057)\tData  0.055 ( 0.032)\tLoss 8.0061e-01 (9.3058e-01)\tAcc@1  71.09 ( 67.44)\tAcc@5  97.66 ( 97.21)\n",
            "Epoch: [11][300/391]\tTime  0.025 ( 0.056)\tData  0.009 ( 0.031)\tLoss 7.6117e-01 (9.3664e-01)\tAcc@1  70.31 ( 67.19)\tAcc@5  96.88 ( 97.13)\n",
            "Epoch: [11][350/391]\tTime  0.042 ( 0.056)\tData  0.022 ( 0.031)\tLoss 9.3568e-01 (9.3740e-01)\tAcc@1  68.75 ( 67.22)\tAcc@5  96.09 ( 97.12)\n",
            "Test: [ 0/79]\tTime  0.281 ( 0.281)\tLoss 9.2513e-01 (9.2513e-01)\tAcc@1  67.97 ( 67.97)\tAcc@5  96.88 ( 96.88)\n",
            "Test: [50/79]\tTime  0.071 ( 0.052)\tLoss 8.7673e-01 (9.5666e-01)\tAcc@1  71.09 ( 67.37)\tAcc@5  97.66 ( 96.71)\n",
            " * Acc@1 67.660 Acc@5 96.700\n",
            "lr: [0.09648882429441258]\n",
            "Epoch: [12][  0/391]\tTime  0.240 ( 0.240)\tData  0.214 ( 0.214)\tLoss 9.7426e-01 (9.7426e-01)\tAcc@1  62.50 ( 62.50)\tAcc@5  96.09 ( 96.09)\n",
            "Epoch: [12][ 50/391]\tTime  0.093 ( 0.055)\tData  0.070 ( 0.029)\tLoss 9.4158e-01 (9.0295e-01)\tAcc@1  67.97 ( 68.24)\tAcc@5  96.88 ( 97.64)\n",
            "Epoch: [12][100/391]\tTime  0.033 ( 0.053)\tData  0.001 ( 0.028)\tLoss 1.0023e+00 (9.0739e-01)\tAcc@1  69.53 ( 68.34)\tAcc@5  96.09 ( 97.50)\n",
            "Epoch: [12][150/391]\tTime  0.027 ( 0.052)\tData  0.002 ( 0.027)\tLoss 7.8680e-01 (8.9869e-01)\tAcc@1  77.34 ( 68.61)\tAcc@5  98.44 ( 97.55)\n",
            "Epoch: [12][200/391]\tTime  0.023 ( 0.057)\tData  0.001 ( 0.032)\tLoss 9.6159e-01 (9.0788e-01)\tAcc@1  67.19 ( 68.41)\tAcc@5  96.88 ( 97.39)\n",
            "Epoch: [12][250/391]\tTime  0.023 ( 0.057)\tData  0.001 ( 0.032)\tLoss 9.1498e-01 (9.1328e-01)\tAcc@1  66.41 ( 68.19)\tAcc@5  97.66 ( 97.34)\n",
            "Epoch: [12][300/391]\tTime  0.046 ( 0.056)\tData  0.001 ( 0.031)\tLoss 1.2285e+00 (9.1150e-01)\tAcc@1  57.03 ( 68.29)\tAcc@5  96.09 ( 97.32)\n",
            "Epoch: [12][350/391]\tTime  0.060 ( 0.055)\tData  0.037 ( 0.030)\tLoss 8.9248e-01 (9.1217e-01)\tAcc@1  68.75 ( 68.28)\tAcc@5  97.66 ( 97.30)\n",
            "Test: [ 0/79]\tTime  0.246 ( 0.246)\tLoss 8.7646e-01 (8.7646e-01)\tAcc@1  68.75 ( 68.75)\tAcc@5  97.66 ( 97.66)\n",
            "Test: [50/79]\tTime  0.039 ( 0.048)\tLoss 1.1053e+00 (1.0327e+00)\tAcc@1  59.38 ( 63.65)\tAcc@5  96.88 ( 96.42)\n",
            " * Acc@1 64.020 Acc@5 96.530\n",
            "lr: [0.09588773128419906]\n",
            "Epoch: [13][  0/391]\tTime  0.243 ( 0.243)\tData  0.201 ( 0.201)\tLoss 1.0299e+00 (1.0299e+00)\tAcc@1  67.97 ( 67.97)\tAcc@5  94.53 ( 94.53)\n",
            "Epoch: [13][ 50/391]\tTime  0.072 ( 0.054)\tData  0.050 ( 0.028)\tLoss 9.0892e-01 (8.7480e-01)\tAcc@1  67.97 ( 69.35)\tAcc@5  97.66 ( 97.67)\n",
            "Epoch: [13][100/391]\tTime  0.062 ( 0.052)\tData  0.040 ( 0.029)\tLoss 7.4692e-01 (8.8793e-01)\tAcc@1  75.78 ( 68.84)\tAcc@5  96.88 ( 97.50)\n",
            "Epoch: [13][150/391]\tTime  0.045 ( 0.052)\tData  0.024 ( 0.028)\tLoss 7.4180e-01 (8.8291e-01)\tAcc@1  74.22 ( 69.25)\tAcc@5  97.66 ( 97.46)\n",
            "Epoch: [13][200/391]\tTime  0.084 ( 0.056)\tData  0.068 ( 0.032)\tLoss 9.3790e-01 (8.8090e-01)\tAcc@1  67.19 ( 69.40)\tAcc@5  98.44 ( 97.48)\n",
            "Epoch: [13][250/391]\tTime  0.028 ( 0.055)\tData  0.006 ( 0.031)\tLoss 1.0241e+00 (8.8903e-01)\tAcc@1  64.84 ( 69.06)\tAcc@5  94.53 ( 97.45)\n",
            "Epoch: [13][300/391]\tTime  0.066 ( 0.055)\tData  0.047 ( 0.030)\tLoss 8.3076e-01 (8.9029e-01)\tAcc@1  67.97 ( 69.09)\tAcc@5  97.66 ( 97.37)\n",
            "Epoch: [13][350/391]\tTime  0.077 ( 0.054)\tData  0.062 ( 0.030)\tLoss 8.9292e-01 (8.8982e-01)\tAcc@1  70.31 ( 69.18)\tAcc@5  99.22 ( 97.39)\n",
            "Test: [ 0/79]\tTime  0.280 ( 0.280)\tLoss 8.7336e-01 (8.7336e-01)\tAcc@1  69.53 ( 69.53)\tAcc@5  96.88 ( 96.88)\n",
            "Test: [50/79]\tTime  0.036 ( 0.051)\tLoss 8.8091e-01 (8.9537e-01)\tAcc@1  68.75 ( 68.75)\tAcc@5  97.66 ( 97.29)\n",
            " * Acc@1 68.660 Acc@5 97.300\n",
            "lr: [0.09524135262330098]\n",
            "Epoch: [14][  0/391]\tTime  0.283 ( 0.283)\tData  0.243 ( 0.243)\tLoss 1.0489e+00 (1.0489e+00)\tAcc@1  64.84 ( 64.84)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [14][ 50/391]\tTime  0.063 ( 0.056)\tData  0.041 ( 0.030)\tLoss 8.5039e-01 (8.3618e-01)\tAcc@1  67.19 ( 70.94)\tAcc@5  97.66 ( 97.98)\n",
            "Epoch: [14][100/391]\tTime  0.058 ( 0.054)\tData  0.035 ( 0.029)\tLoss 9.5247e-01 (8.6389e-01)\tAcc@1  68.75 ( 70.16)\tAcc@5  96.88 ( 97.77)\n",
            "Epoch: [14][150/391]\tTime  0.040 ( 0.053)\tData  0.017 ( 0.028)\tLoss 1.0215e+00 (8.6934e-01)\tAcc@1  71.88 ( 70.20)\tAcc@5  93.75 ( 97.54)\n",
            "Epoch: [14][200/391]\tTime  0.080 ( 0.057)\tData  0.060 ( 0.032)\tLoss 6.7805e-01 (8.7243e-01)\tAcc@1  76.56 ( 70.11)\tAcc@5 100.00 ( 97.59)\n",
            "Epoch: [14][250/391]\tTime  0.079 ( 0.056)\tData  0.063 ( 0.032)\tLoss 7.7564e-01 (8.7130e-01)\tAcc@1  74.22 ( 70.17)\tAcc@5  96.88 ( 97.56)\n",
            "Epoch: [14][300/391]\tTime  0.093 ( 0.055)\tData  0.076 ( 0.031)\tLoss 1.0445e+00 (8.6763e-01)\tAcc@1  67.19 ( 70.26)\tAcc@5  93.75 ( 97.61)\n",
            "Epoch: [14][350/391]\tTime  0.075 ( 0.054)\tData  0.053 ( 0.031)\tLoss 7.5773e-01 (8.6900e-01)\tAcc@1  72.66 ( 70.17)\tAcc@5  98.44 ( 97.58)\n",
            "Test: [ 0/79]\tTime  0.263 ( 0.263)\tLoss 7.5873e-01 (7.5873e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5  95.31 ( 95.31)\n",
            "Test: [50/79]\tTime  0.011 ( 0.049)\tLoss 8.3711e-01 (8.6616e-01)\tAcc@1  72.66 ( 69.64)\tAcc@5  98.44 ( 97.72)\n",
            " * Acc@1 69.840 Acc@5 97.720\n",
            "lr: [0.0945503262094184]\n",
            "Epoch: [15][  0/391]\tTime  0.256 ( 0.256)\tData  0.212 ( 0.212)\tLoss 7.7784e-01 (7.7784e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [15][ 50/391]\tTime  0.058 ( 0.055)\tData  0.034 ( 0.029)\tLoss 9.6423e-01 (8.5549e-01)\tAcc@1  71.09 ( 70.57)\tAcc@5  99.22 ( 97.56)\n",
            "Epoch: [15][100/391]\tTime  0.073 ( 0.054)\tData  0.047 ( 0.028)\tLoss 9.0890e-01 (8.5180e-01)\tAcc@1  67.19 ( 70.63)\tAcc@5  99.22 ( 97.65)\n",
            "Epoch: [15][150/391]\tTime  0.141 ( 0.053)\tData  0.092 ( 0.028)\tLoss 8.7874e-01 (8.5344e-01)\tAcc@1  67.97 ( 70.61)\tAcc@5  97.66 ( 97.57)\n",
            "Epoch: [15][200/391]\tTime  0.038 ( 0.058)\tData  0.001 ( 0.032)\tLoss 8.9756e-01 (8.5476e-01)\tAcc@1  67.19 ( 70.41)\tAcc@5  99.22 ( 97.62)\n",
            "Epoch: [15][250/391]\tTime  0.035 ( 0.056)\tData  0.001 ( 0.031)\tLoss 7.3189e-01 (8.5256e-01)\tAcc@1  75.00 ( 70.58)\tAcc@5  99.22 ( 97.61)\n",
            "Epoch: [15][300/391]\tTime  0.044 ( 0.055)\tData  0.029 ( 0.030)\tLoss 9.1378e-01 (8.5442e-01)\tAcc@1  63.28 ( 70.53)\tAcc@5  98.44 ( 97.58)\n",
            "Epoch: [15][350/391]\tTime  0.048 ( 0.054)\tData  0.031 ( 0.030)\tLoss 8.2406e-01 (8.5783e-01)\tAcc@1  72.66 ( 70.41)\tAcc@5  96.88 ( 97.57)\n",
            "Test: [ 0/79]\tTime  0.223 ( 0.223)\tLoss 7.9653e-01 (7.9653e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5  97.66 ( 97.66)\n",
            "Test: [50/79]\tTime  0.052 ( 0.051)\tLoss 1.0303e+00 (8.8044e-01)\tAcc@1  66.41 ( 70.13)\tAcc@5  96.09 ( 97.49)\n",
            " * Acc@1 70.030 Acc@5 97.410\n",
            "lr: [0.09381533400219319]\n",
            "Epoch: [16][  0/391]\tTime  0.289 ( 0.289)\tData  0.247 ( 0.247)\tLoss 8.0090e-01 (8.0090e-01)\tAcc@1  71.09 ( 71.09)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [16][ 50/391]\tTime  0.085 ( 0.057)\tData  0.068 ( 0.033)\tLoss 6.1889e-01 (8.2369e-01)\tAcc@1  78.12 ( 71.42)\tAcc@5  99.22 ( 97.61)\n",
            "Epoch: [16][100/391]\tTime  0.083 ( 0.053)\tData  0.061 ( 0.031)\tLoss 8.3527e-01 (8.2858e-01)\tAcc@1  74.22 ( 71.68)\tAcc@5  97.66 ( 97.62)\n",
            "Epoch: [16][150/391]\tTime  0.083 ( 0.052)\tData  0.060 ( 0.030)\tLoss 7.3090e-01 (8.3222e-01)\tAcc@1  72.66 ( 71.43)\tAcc@5  99.22 ( 97.63)\n",
            "Epoch: [16][200/391]\tTime  0.024 ( 0.057)\tData  0.001 ( 0.033)\tLoss 7.5699e-01 (8.2710e-01)\tAcc@1  75.78 ( 71.58)\tAcc@5  97.66 ( 97.70)\n",
            "Epoch: [16][250/391]\tTime  0.028 ( 0.056)\tData  0.001 ( 0.033)\tLoss 8.9296e-01 (8.2851e-01)\tAcc@1  70.31 ( 71.55)\tAcc@5  95.31 ( 97.74)\n",
            "Epoch: [16][300/391]\tTime  0.060 ( 0.059)\tData  0.037 ( 0.035)\tLoss 7.2373e-01 (8.2874e-01)\tAcc@1  78.12 ( 71.56)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [16][350/391]\tTime  0.035 ( 0.058)\tData  0.020 ( 0.034)\tLoss 7.2081e-01 (8.3336e-01)\tAcc@1  75.78 ( 71.32)\tAcc@5  96.88 ( 97.67)\n",
            "Test: [ 0/79]\tTime  0.193 ( 0.193)\tLoss 7.2072e-01 (7.2072e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  97.66 ( 97.66)\n",
            "Test: [50/79]\tTime  0.029 ( 0.037)\tLoss 9.9588e-01 (8.8813e-01)\tAcc@1  67.97 ( 70.17)\tAcc@5  97.66 ( 97.99)\n",
            " * Acc@1 70.260 Acc@5 97.990\n",
            "lr: [0.0930371013501972]\n",
            "Epoch: [17][  0/391]\tTime  0.241 ( 0.241)\tData  0.214 ( 0.214)\tLoss 7.7986e-01 (7.7986e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [17][ 50/391]\tTime  0.077 ( 0.054)\tData  0.054 ( 0.029)\tLoss 9.2768e-01 (8.2318e-01)\tAcc@1  66.41 ( 71.83)\tAcc@5  96.88 ( 97.82)\n",
            "Epoch: [17][100/391]\tTime  0.063 ( 0.054)\tData  0.047 ( 0.029)\tLoss 8.1816e-01 (8.2229e-01)\tAcc@1  69.53 ( 71.76)\tAcc@5  96.88 ( 97.74)\n",
            "Epoch: [17][150/391]\tTime  0.049 ( 0.058)\tData  0.003 ( 0.032)\tLoss 8.0778e-01 (8.2623e-01)\tAcc@1  73.44 ( 71.52)\tAcc@5  97.66 ( 97.76)\n",
            "Epoch: [17][200/391]\tTime  0.039 ( 0.058)\tData  0.001 ( 0.033)\tLoss 9.5696e-01 (8.2323e-01)\tAcc@1  67.97 ( 71.63)\tAcc@5  97.66 ( 97.82)\n",
            "Epoch: [17][250/391]\tTime  0.024 ( 0.057)\tData  0.001 ( 0.031)\tLoss 8.5142e-01 (8.2098e-01)\tAcc@1  69.53 ( 71.69)\tAcc@5  97.66 ( 97.82)\n",
            "Epoch: [17][300/391]\tTime  0.021 ( 0.056)\tData  0.006 ( 0.031)\tLoss 9.1991e-01 (8.2720e-01)\tAcc@1  71.09 ( 71.42)\tAcc@5  96.88 ( 97.77)\n",
            "Epoch: [17][350/391]\tTime  0.021 ( 0.055)\tData  0.001 ( 0.030)\tLoss 8.8482e-01 (8.2729e-01)\tAcc@1  69.53 ( 71.39)\tAcc@5  96.88 ( 97.78)\n",
            "Test: [ 0/79]\tTime  0.175 ( 0.175)\tLoss 8.4275e-01 (8.4275e-01)\tAcc@1  74.22 ( 74.22)\tAcc@5  97.66 ( 97.66)\n",
            "Test: [50/79]\tTime  0.037 ( 0.034)\tLoss 8.9581e-01 (8.0419e-01)\tAcc@1  71.88 ( 72.56)\tAcc@5  96.88 ( 98.02)\n",
            " * Acc@1 72.680 Acc@5 98.110\n",
            "lr: [0.09221639627510078]\n",
            "Epoch: [18][  0/391]\tTime  0.255 ( 0.255)\tData  0.218 ( 0.218)\tLoss 8.0107e-01 (8.0107e-01)\tAcc@1  68.75 ( 68.75)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [18][ 50/391]\tTime  0.036 ( 0.054)\tData  0.001 ( 0.031)\tLoss 8.3672e-01 (8.1665e-01)\tAcc@1  72.66 ( 71.74)\tAcc@5  99.22 ( 97.95)\n",
            "Epoch: [18][100/391]\tTime  0.053 ( 0.053)\tData  0.032 ( 0.029)\tLoss 8.3140e-01 (8.1597e-01)\tAcc@1  70.31 ( 71.82)\tAcc@5  96.88 ( 97.83)\n",
            "Epoch: [18][150/391]\tTime  0.048 ( 0.057)\tData  0.000 ( 0.033)\tLoss 6.6463e-01 (8.1164e-01)\tAcc@1  77.34 ( 72.02)\tAcc@5  99.22 ( 97.85)\n",
            "Epoch: [18][200/391]\tTime  0.033 ( 0.057)\tData  0.007 ( 0.032)\tLoss 9.2267e-01 (8.0849e-01)\tAcc@1  67.19 ( 72.17)\tAcc@5  98.44 ( 97.85)\n",
            "Epoch: [18][250/391]\tTime  0.055 ( 0.056)\tData  0.032 ( 0.032)\tLoss 9.7184e-01 (8.1303e-01)\tAcc@1  69.53 ( 71.96)\tAcc@5  95.31 ( 97.82)\n",
            "Epoch: [18][300/391]\tTime  0.019 ( 0.055)\tData  0.001 ( 0.031)\tLoss 7.3336e-01 (8.0967e-01)\tAcc@1  70.31 ( 72.08)\tAcc@5  98.44 ( 97.87)\n",
            "Epoch: [18][350/391]\tTime  0.075 ( 0.055)\tData  0.059 ( 0.031)\tLoss 5.3483e-01 (8.0693e-01)\tAcc@1  84.38 ( 72.24)\tAcc@5 100.00 ( 97.88)\n",
            "Test: [ 0/79]\tTime  0.177 ( 0.177)\tLoss 8.2511e-01 (8.2511e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5  95.31 ( 95.31)\n",
            "Test: [50/79]\tTime  0.017 ( 0.036)\tLoss 7.9559e-01 (8.2810e-01)\tAcc@1  77.34 ( 72.56)\tAcc@5  96.09 ( 97.95)\n",
            " * Acc@1 72.140 Acc@5 98.030\n",
            "lr: [0.09135402871372812]\n",
            "Epoch: [19][  0/391]\tTime  0.243 ( 0.243)\tData  0.203 ( 0.203)\tLoss 6.9415e-01 (6.9415e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [19][ 50/391]\tTime  0.061 ( 0.055)\tData  0.043 ( 0.031)\tLoss 8.2957e-01 (7.6135e-01)\tAcc@1  74.22 ( 74.17)\tAcc@5  97.66 ( 98.22)\n",
            "Epoch: [19][100/391]\tTime  0.036 ( 0.053)\tData  0.001 ( 0.030)\tLoss 8.2750e-01 (7.9352e-01)\tAcc@1  68.75 ( 72.52)\tAcc@5  97.66 ( 98.13)\n",
            "Epoch: [19][150/391]\tTime  0.039 ( 0.056)\tData  0.000 ( 0.032)\tLoss 8.4557e-01 (8.0141e-01)\tAcc@1  75.00 ( 72.22)\tAcc@5  96.88 ( 98.01)\n",
            "Epoch: [19][200/391]\tTime  0.077 ( 0.057)\tData  0.055 ( 0.032)\tLoss 8.0010e-01 (7.9791e-01)\tAcc@1  78.91 ( 72.46)\tAcc@5  98.44 ( 97.98)\n",
            "Epoch: [19][250/391]\tTime  0.072 ( 0.056)\tData  0.057 ( 0.031)\tLoss 6.4207e-01 (7.9714e-01)\tAcc@1  77.34 ( 72.52)\tAcc@5  98.44 ( 97.97)\n",
            "Epoch: [19][300/391]\tTime  0.070 ( 0.055)\tData  0.049 ( 0.031)\tLoss 7.9731e-01 (8.0044e-01)\tAcc@1  72.66 ( 72.39)\tAcc@5  96.88 ( 97.95)\n",
            "Epoch: [19][350/391]\tTime  0.051 ( 0.055)\tData  0.029 ( 0.031)\tLoss 7.9687e-01 (8.0432e-01)\tAcc@1  71.09 ( 72.39)\tAcc@5  97.66 ( 97.90)\n",
            "Test: [ 0/79]\tTime  0.243 ( 0.243)\tLoss 6.7569e-01 (6.7569e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5  96.88 ( 96.88)\n",
            "Test: [50/79]\tTime  0.041 ( 0.038)\tLoss 8.8891e-01 (8.2249e-01)\tAcc@1  71.88 ( 71.06)\tAcc@5  94.53 ( 97.78)\n",
            " * Acc@1 71.010 Acc@5 97.910\n",
            "lr: [0.09045084971874741]\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(START_EPOCH, EPOCHS):\n",
        "#    adjust_learning_rate(optimizer, epoch)\n",
        "\n",
        "    # train for one epoch\n",
        "    train(train_loader, model, criterion, optimizer, epoch)\n",
        "\n",
        "\n",
        "    # evaluate on validation set\n",
        "    acc1 = validate(val_loader, model, criterion)\n",
        "\n",
        "    # remember best acc@1 and save checkpoint\n",
        "    is_best = acc1 > best_acc1\n",
        "    best_acc1 = max(acc1, best_acc1)\n",
        "\n",
        "\n",
        "    save_checkpoint({\n",
        "        'epoch': epoch + 1,\n",
        "        'arch': ARCH,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'best_acc1': best_acc1,\n",
        "        'optimizer' : optimizer.state_dict(),\n",
        "    }, is_best)\n",
        "    \n",
        "    scheduler.step()\n",
        "    print('lr: ' + str(scheduler.get_last_lr()))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}